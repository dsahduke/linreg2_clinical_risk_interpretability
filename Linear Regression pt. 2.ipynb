{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Regression (continued)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Last time, we saw that linear regression could be written as\n",
    "$$ y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 ... + \\epsilon_i,  \\epsilon_i \\sim N(0, \\sigma^2) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In addition, we saw different ways that you could use to estimate the coefficients, $\\beta$. However, we did not really touch upon the predictors (otherwise known as covariates, independent variables, features, etc). In practice, as long as the x values are numeric, they can be included in the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For example, if we have some variable $y$, and we want to use $age = x_1$ and $gender = x_2$ where gender is equal to 1 for male and 0 for female:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ y = \\beta_0 + \\beta_1x_1^2 + \\beta_2x_2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$y = \\beta_0 + \\beta_1 \\log(x_1) + \\beta x_2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ y = \\beta_0 + \\beta_1x_1*x_2 + \\beta_2x_1 + \\beta_3x_2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### this is no longer linear:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ y = \\beta_0 + \\beta_1x_1 + \\beta_2^2x_2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Categorical Variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Many times, you will have what are known as *categorical* variables, meaning that they take several discrete values. For example, gender and race are common examples of *categorical* variables. How do we use these in linear regression (and other models?). We can create dummy variables/indicator variables! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If the categorical variable is binary, we can simply create a variable called gender, where x=1 is equal to male or female, and x=0 is the opposite. However, if we have a categorical variable with $k$ possible conditions, we can make $k-1$ columns to represent that. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Why $k-1$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "last time, we fit a model that was:\n",
    "\n",
    "`num_lab_procedures = intercept + num_medications`\n",
    "\n",
    "Let's add race!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "diabetes_df = pd.read_csv(\"../Assignments/hw2/data/diabetic_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "y = diabetes_df['num_lab_procedures'].values\n",
    "x = np.column_stack((np.ones((diabetes_df.shape[0])), diabetes_df['num_medications'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "unique_race = diabetes_df.groupby(['encounter_id'])['race'].first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>?</th>\n",
       "      <th>AfricanAmerican</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Caucasian</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>Other</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encounter_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12522</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15738</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16680</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28236</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35754</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ?  AfricanAmerican  Asian  Caucasian  Hispanic  Other\n",
       "encounter_id                                                       \n",
       "12522         0                0      0          1         0      0\n",
       "15738         0                0      0          1         0      0\n",
       "16680         0                0      0          1         0      0\n",
       "28236         0                1      0          0         0      0\n",
       "35754         0                0      0          1         0      0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies = pd.get_dummies(unique_race)\n",
    "dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    101766\n",
       "dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies.apply(sum, axis = 1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 1., 18.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 1., 13.,  0., ...,  1.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 1.,  9.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 1., 21.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 1.,  3.,  0., ...,  1.,  0.,  0.]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.column_stack((x, dummies.values))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  0.,  0.,  1.,  0.],\n",
       "       [ 1., 18.,  0.,  0.,  1.,  0.],\n",
       "       [ 1., 13.,  0.,  0.,  1.,  0.],\n",
       "       ...,\n",
       "       [ 1.,  9.,  0.,  0.,  1.,  0.],\n",
       "       [ 1., 21.,  0.,  0.,  1.,  0.],\n",
       "       [ 1.,  3.,  0.,  0.,  1.,  0.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x # Design matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Quick Note on Design Matrices (model matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A *design matrix*, or model matrix, must have 1 row per observation, where each column is a variable that characterizes the observation. This is usually known as having *tidy* data. Almost all machine learning models assume this format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.05673779e+03,  5.77584673e-01, -2.08963037e+03, -2.13861914e+03,\n",
       "       -2.16849365e+03, -2.14056641e+03, -2.06651150e+03, -2.06993795e+03])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.dot(np.linalg.inv(np.dot(np.transpose(x), x)), np.transpose(x)), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model = sm.OLS(y, x).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.073\n",
      "Model:                            OLS   Adj. R-squared:                  0.073\n",
      "Method:                 Least Squares   F-statistic:                     1343.\n",
      "Date:                Tue, 12 Feb 2019   Prob (F-statistic):               0.00\n",
      "Time:                        11:20:13   Log-Likelihood:            -4.4371e+05\n",
      "No. Observations:              101766   AIC:                         8.874e+05\n",
      "Df Residuals:                  101759   BIC:                         8.875e+05\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         28.5211      0.180    158.387      0.000      28.168      28.874\n",
      "x1             0.6539      0.007     89.332      0.000       0.640       0.668\n",
      "x2             5.2752      0.370     14.265      0.000       4.550       6.000\n",
      "x3             5.5078      0.193     28.538      0.000       5.130       5.886\n",
      "x4             4.0000      0.651      6.148      0.000       2.725       5.275\n",
      "x5             3.6640      0.166     22.067      0.000       3.339       3.989\n",
      "x6             5.0981      0.387     13.189      0.000       4.340       5.856\n",
      "x7             4.9760      0.440     11.298      0.000       4.113       5.839\n",
      "==============================================================================\n",
      "Omnibus:                     1678.919   Durbin-Watson:                   1.842\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1535.362\n",
      "Skew:                          -0.256   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.685   Cond. No.                     4.97e+16\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.34e-26. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Multicollinearity:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "When one or more of the predictors in a linear model can be written as a linear combination of other predictors, this is known as *perfect multicollinearity*. In this case, it is not possible to obtain the correct estimates for the model coefficients in linear regression. If some of the predictors are highly correlated with themselves, this also results in multicollinearity.\n",
    "\n",
    "Oftentimes, when you have multicollinearity, you will get extremely large standard errors in your estimates, and many of the hypothesis tests will not reject, even when the model as a whole is significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Solution: set 1 base case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x = np.column_stack((np.ones((diabetes_df.shape[0])), diabetes_df['num_medications'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>?</th>\n",
       "      <th>AfricanAmerican</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Caucasian</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>Other</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encounter_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12522</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15738</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16680</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28236</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35754</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ?  AfricanAmerican  Asian  Caucasian  Hispanic  Other\n",
       "encounter_id                                                       \n",
       "12522         0                0      0          1         0      0\n",
       "15738         0                0      0          1         0      0\n",
       "16680         0                0      0          1         0      0\n",
       "28236         0                1      0          0         0      0\n",
       "35754         0                0      0          1         0      0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_race = diabetes_df.groupby(['encounter_id'])['race'].first()\n",
    "dummies = pd.get_dummies(unique_race)\n",
    "dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x = np.column_stack((x, dummies.iloc[:, 1:5].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33.67666855,  0.6538995 ,  0.35181106, -1.15595682, -1.49197443,\n",
       "       -0.05784078])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.dot(np.linalg.inv(np.dot(np.transpose(x), x)), np.transpose(x)), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model = sm.OLS(y, x).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.073\n",
      "Model:                            OLS   Adj. R-squared:                  0.073\n",
      "Method:                 Least Squares   F-statistic:                     1612.\n",
      "Date:                Tue, 12 Feb 2019   Prob (F-statistic):               0.00\n",
      "Time:                        11:23:50   Log-Likelihood:            -4.4371e+05\n",
      "No. Observations:              101766   AIC:                         8.874e+05\n",
      "Df Residuals:                  101760   BIC:                         8.875e+05\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         33.6767      0.328    102.522      0.000      33.033      34.320\n",
      "x1             0.6539      0.007     89.338      0.000       0.640       0.668\n",
      "x2             0.3518      0.337      1.044      0.297      -0.309       1.012\n",
      "x3            -1.1560      0.809     -1.429      0.153      -2.742       0.430\n",
      "x4            -1.4920      0.316     -4.726      0.000      -2.111      -0.873\n",
      "x5            -0.0578      0.521     -0.111      0.912      -1.078       0.963\n",
      "==============================================================================\n",
      "Omnibus:                     1680.197   Durbin-Watson:                   1.842\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1536.506\n",
      "Skew:                          -0.256   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.685   Cond. No.                         265.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Covariates as controls\n",
    "\n",
    "One interpretation of covariates in the linear regression model is that they are controls. If they are included in the model, it means that they are controlled for. It is possible to say, holding values of all of the other predictors constant, the an increase in the response variable $y$ is related to a $\\beta$ amount of increase in the variable, or vice versa.\n",
    "\n",
    "$$ y = \\beta_0 + \\beta_1x_1^2 + \\beta_2x_2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Interaction variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Sometimes, it may be useful to use interaction variables. In regular regression, where no interactions are specified, the coefficients $\\beta$ represent the unique impact that each covariate $x$ has on the response $y$. However, it is often the case that we believe that the effect on $y$ for different values of $x$ also depend on interactions between the $x$ variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In the above regression, we fit `num_lab_procedures = intercept + num_medications + race1 + race2...`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "However, what if we believe that, the assocation between the number of lab procudures and the number of medications is actually different depending on your race? We could capture that in the following way:\n",
    "\n",
    "`num_lab_procedures = intercept + num_medications + race1 + num_medications * race1 + race2 + num_medications * race2...`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now, the effect of the number of medications on the number of lab procedures is decomposed into the part that is not specific to race, and those that are. This is a fairly common procedure in statistical analysis when there is some suspected dependence between the predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why not include everything?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Why, if I had a ton of data, wouldn't I just use every variable?\n",
    "\n",
    "If I had 20 variables, and then did pairwise interactions between them, I would have 20 + (20 * 19 /2) + 1(intercept) terms in my model. That's 211 variables. Why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Last time, we discussed the the $R^2$ was used in model-checking in a traditional regression analysis approach. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$var(y) = var(\\boldsymbol{\\beta}^T\\textbf{x}) + var(\\epsilon)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$R^2 = \\frac{var(\\boldsymbol{\\beta}^T\\textbf{x})}{var(y)} = \\frac{\\Sigma_{i=1}^n(\\hat{y}_i - \\bar{y})^2}{\\Sigma_{i=1}^n(y_i - \\bar{y})} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "However, we can always make $R^2$ larger if we just keep adding terms! This is why $R^2$ is not the best choice by itself for model validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Curse of Dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](./assets/cod.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For a uniformly random point in the box in d dimensions with length 2 in each dimension, what is the probability that the random vector is in the unit ball in d dimensions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: \n",
    "\n",
    "Plot the ratio of the volume of an $n$-ball (a ball in n-dimensions) with radius 1 versus the volume of a hypercube with a side length of 2 for dimensions 1 through 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volume of an *n*-ball\n",
    "\n",
    "$$V_n(R) = \\frac{\\pi^{n/2}}{\\Gamma(\\frac{n}{2} + 1)}R^n$$\n",
    "\n",
    "where $\\Gamma$ is the generalized gamma function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from scipy.special import gamma\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# math.pi\n",
    "# the gamma function has been imported as gamma\n",
    "def get_hypersphere_volume(dimension, radius):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hypercube_volume(dimension, length):\n",
    "    pass "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](./assets/xkcd.png)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
